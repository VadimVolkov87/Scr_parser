# Приложение для асинхронного парсинга страниц PEP

Репозиторий `Scr_parser` содержит приложение для асинхронного парсинга страниц документации Python. Результатами парсинга являются перечень документов PEP с номером, назаванием и статусом (выводится в файл формата csv) и таблица с количеством докуметов PEP определенного статуса (выводится в отдельный файл csv).

## Стек приложения

Приложение создано на основе:

* Python
* scrapy
* lxml
* Twisted

## Для запуска проекта необходимо

Клонировать репозиторий:

```bash
git clone https://github.com/VadimVolkov87/Scr_parser
```

Перейти в корневую папку приложения:

```bash
cd Scr_parser
```

Создать и активировать виртуальное окружение:

```bash
python -m venv venv
```

```bash
source venv/Scripts/activate
```

Установить пакеты из файла зависимостей:

```bash
pip install -r requirements.txt
```

Запустить парсер командой терминала из корневой директории проекта:

```bash
scrapy crawl pep
```

## Автор проекта

Вадим Волков - разработка

[Вадим Волков](https://github.com/VadimVolkov87/)
